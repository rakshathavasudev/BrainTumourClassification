{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T00:34:16.687531Z",
     "iopub.status.busy": "2025-05-14T00:34:16.686802Z",
     "iopub.status.idle": "2025-05-14T00:34:22.973018Z",
     "shell.execute_reply": "2025-05-14T00:34:22.971882Z",
     "shell.execute_reply.started": "2025-05-14T00:34:16.687500Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from torchvision.models import vgg19\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T00:41:07.981395Z",
     "iopub.status.busy": "2025-05-14T00:41:07.981046Z",
     "iopub.status.idle": "2025-05-14T00:41:07.987917Z",
     "shell.execute_reply": "2025-05-14T00:41:07.986938Z",
     "shell.execute_reply.started": "2025-05-14T00:41:07.981375Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1. Dataset Loader ------------------------------------------------------\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform_hr, transform_lr):\n",
    "        self.hr_images = []\n",
    "        for class_dir in os.listdir(root_dir):\n",
    "            self.hr_images += glob.glob(os.path.join(root_dir, class_dir, '*.png'))\n",
    "        self.transform_hr = transform_hr\n",
    "        self.transform_lr = transform_lr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hr_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.hr_images[idx]).convert('RGB')\n",
    "        hr = self.transform_hr(img)\n",
    "        lr = self.transform_lr(img)\n",
    "        return lr, hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T00:41:10.816171Z",
     "iopub.status.busy": "2025-05-14T00:41:10.815875Z",
     "iopub.status.idle": "2025-05-14T00:41:10.823457Z",
     "shell.execute_reply": "2025-05-14T00:41:10.822500Z",
     "shell.execute_reply.started": "2025-05-14T00:41:10.816152Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 2. Generator (MetaSR-style) --------------------------------------------\n",
    "class MetaSRGenerator(nn.Module):\n",
    "    def __init__(self, scale):\n",
    "        super(MetaSRGenerator, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.res_blocks = nn.Sequential(\n",
    "            *[nn.Sequential(\n",
    "                nn.Conv2d(64, 64, 3, 1, 1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(64, 64, 3, 1, 1)) for _ in range(5)]\n",
    "        )\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.Conv2d(64, 256, 3, 1, 1),\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 3, 3, 1, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        res = self.res_blocks(x)\n",
    "        x = x + res  # skip connection\n",
    "        return self.upsample(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T00:41:12.408081Z",
     "iopub.status.busy": "2025-05-14T00:41:12.407733Z",
     "iopub.status.idle": "2025-05-14T00:41:12.415281Z",
     "shell.execute_reply": "2025-05-14T00:41:12.414357Z",
     "shell.execute_reply.started": "2025-05-14T00:41:12.408055Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 3. Discriminator --------------------------------------------------------\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T00:41:15.081781Z",
     "iopub.status.busy": "2025-05-14T00:41:15.081485Z",
     "iopub.status.idle": "2025-05-14T00:41:15.087766Z",
     "shell.execute_reply": "2025-05-14T00:41:15.086857Z",
     "shell.execute_reply.started": "2025-05-14T00:41:15.081760Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 4. Weight Prediction Network -------------------------------------------\n",
    "class WeightPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WeightPredictor, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 1, 3, 1, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T00:41:17.051117Z",
     "iopub.status.busy": "2025-05-14T00:41:17.050770Z",
     "iopub.status.idle": "2025-05-14T00:41:17.057133Z",
     "shell.execute_reply": "2025-05-14T00:41:17.056243Z",
     "shell.execute_reply.started": "2025-05-14T00:41:17.051095Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 5. Perceptual Loss -----------------------------------------------------\n",
    "class VGGPerceptualLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGPerceptualLoss, self).__init__()\n",
    "        vgg = vgg19(pretrained=True).features[:36].eval()\n",
    "        for param in vgg.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.vgg = vgg\n",
    "\n",
    "    def forward(self, sr, hr):\n",
    "        return F.l1_loss(self.vgg(sr), self.vgg(hr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T00:41:19.936985Z",
     "iopub.status.busy": "2025-05-14T00:41:19.936645Z",
     "iopub.status.idle": "2025-05-14T00:41:19.946848Z",
     "shell.execute_reply": "2025-05-14T00:41:19.945723Z",
     "shell.execute_reply.started": "2025-05-14T00:41:19.936957Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 6. Training Loop --------------------------------------------------------\n",
    "def train_metasr_gan(train_loader, num_epochs=20):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    G = MetaSRGenerator(scale=2).to(device)\n",
    "    D = Discriminator().to(device)\n",
    "    W = WeightPredictor().to(device)\n",
    "\n",
    "    perceptual_loss = VGGPerceptualLoss().to(device)\n",
    "    bce_loss = nn.BCELoss()\n",
    "    l1_loss = nn.L1Loss()\n",
    "\n",
    "    opt_G = torch.optim.Adam(G.parameters(), lr=1e-4)\n",
    "    opt_D = torch.optim.Adam(D.parameters(), lr=1e-4)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (lr, hr) in enumerate(train_loader):\n",
    "            lr, hr = lr.to(device), hr.to(device)\n",
    "\n",
    "            # Train Discriminator\n",
    "            D.zero_grad()\n",
    "            real_out = D(hr)\n",
    "            fake = G(lr)\n",
    "            fake_out = D(fake.detach())\n",
    "            real_loss = bce_loss(real_out, torch.ones_like(real_out))\n",
    "            fake_loss = bce_loss(fake_out, torch.zeros_like(fake_out))\n",
    "            d_loss = (real_loss + fake_loss) * 0.5\n",
    "            d_loss.backward()\n",
    "            opt_D.step()\n",
    "\n",
    "            # Train Generator\n",
    "            G.zero_grad()\n",
    "            fake_out = D(fake)\n",
    "            adv_loss = bce_loss(fake_out, torch.ones_like(fake_out))\n",
    "            content_loss = perceptual_loss(fake, hr)\n",
    "            pixel_loss = l1_loss(fake, hr)\n",
    "            g_loss = content_loss + 0.001 * adv_loss + 0.01 * pixel_loss\n",
    "            g_loss.backward()\n",
    "            opt_G.step()\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i}], D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T00:41:22.858869Z",
     "iopub.status.busy": "2025-05-14T00:41:22.858537Z",
     "iopub.status.idle": "2025-05-14T00:41:22.887962Z",
     "shell.execute_reply": "2025-05-14T00:41:22.886788Z",
     "shell.execute_reply.started": "2025-05-14T00:41:22.858845Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 7. Prepare Dataloader ---------------------------------------------------\n",
    "transform_hr = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_lr = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),  # 2x downsampling\n",
    "    transforms.Resize((224, 224)),  # simulate upscaling\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = MRIDataset(\"/kaggle/input/dataset-new/dataset_new/1/Training\", transform_hr, transform_lr)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# 8. Launch Training ------------------------------------------------------\n",
    "train_metasr_gan(train_loader)\n",
    "\n",
    "# Done. You can extend with validation loop + checkpoint saving next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Diffusion part not needed-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T17:00:59.010330Z",
     "iopub.status.busy": "2025-05-05T17:00:59.009798Z",
     "iopub.status.idle": "2025-05-05T17:00:59.016648Z",
     "shell.execute_reply": "2025-05-05T17:00:59.015826Z",
     "shell.execute_reply.started": "2025-05-05T17:00:59.010310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def denoise_images(model, noise_scheduler, test_loader, device, save_dir, class_names):\n",
    "    model.eval()\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    with torch.no_grad():\n",
    "        for i, (img, label) in enumerate(tqdm(test_loader)):\n",
    "            img = img.to(device)\n",
    "            noise = torch.randn_like(img)\n",
    "            t = torch.randint(0, noise_scheduler.config.num_train_timesteps, (1,), device=device).long()\n",
    "            noisy_img = noise_scheduler.add_noise(img, noise, t)\n",
    "            denoised = model(noisy_img, t).sample\n",
    "\n",
    "            for j in range(img.size(0)):  # batch-wise saving\n",
    "                class_name = class_names[label[j].item()]\n",
    "                class_dir = os.path.join(save_dir, class_name)\n",
    "                os.makedirs(class_dir, exist_ok=True)\n",
    "                save_image(denoised[j], os.path.join(class_dir, f\"img_{i}_{j}.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T17:01:15.377614Z",
     "iopub.status.busy": "2025-05-05T17:01:15.376930Z",
     "iopub.status.idle": "2025-05-05T17:01:15.382670Z",
     "shell.execute_reply": "2025-05-05T17:01:15.381885Z",
     "shell.execute_reply.started": "2025-05-05T17:01:15.377589Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "\n",
    "def convert_images_to_rgb_resize(input_dir, output_dir, size=(128, 128)):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for class_name in os.listdir(input_dir):\n",
    "        class_path = os.path.join(input_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        for file_name in os.listdir(class_path):\n",
    "            if file_name.endswith(\".png\"):\n",
    "                img_path = os.path.join(class_path, file_name)\n",
    "                img = Image.open(img_path).convert(\"RGB\").resize(size)\n",
    "                out_class_dir = os.path.join(output_dir, class_name)\n",
    "                os.makedirs(out_class_dir, exist_ok=True)\n",
    "                img.save(os.path.join(out_class_dir, file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T16:27:19.733397Z",
     "iopub.status.busy": "2025-05-05T16:27:19.732685Z",
     "iopub.status.idle": "2025-05-05T16:27:19.737991Z",
     "shell.execute_reply": "2025-05-05T16:27:19.737352Z",
     "shell.execute_reply.started": "2025-05-05T16:27:19.733376Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_keras_model(model_path, img_dir, img_size):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    generator = datagen.flow_from_directory(\n",
    "        img_dir,\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    model = load_model(model_path)\n",
    "    preds = model.predict(generator)\n",
    "    pred_classes = np.argmax(preds, axis=1)\n",
    "    true_labels = generator.classes  # ✅ Correct true labels\n",
    "    acc = accuracy_score(true_labels, pred_classes)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T16:42:51.834480Z",
     "iopub.status.busy": "2025-05-05T16:42:51.833976Z",
     "iopub.status.idle": "2025-05-05T16:42:54.222037Z",
     "shell.execute_reply": "2025-05-05T16:42:54.221462Z",
     "shell.execute_reply.started": "2025-05-05T16:42:51.834458Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "IMG_SIZE = 128  # Assuming diffusion model and CNN both use 128x128\n",
    "\n",
    "# Step 1: Define transform (grayscale if single channel)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.Grayscale(num_output_channels=1),  # ensure 1-channel input\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Step 2: Create dataset\n",
    "test_dataset = datasets.ImageFolder(root='/kaggle/input/dataset-new/dataset_new/1/Testing', transform=transform)\n",
    "\n",
    "# Step 3: Create DataLoader\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T17:16:54.938186Z",
     "iopub.status.busy": "2025-05-05T17:16:54.937922Z",
     "iopub.status.idle": "2025-05-05T17:16:55.705027Z",
     "shell.execute_reply": "2025-05-05T17:16:55.704349Z",
     "shell.execute_reply.started": "2025-05-05T17:16:54.938167Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">186624</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">23,888,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m186624\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │      \u001b[38;5;34m23,888,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m516\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,907,910</span> (91.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,907,910\u001b[0m (91.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,907,908</span> (91.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,907,908\u001b[0m (91.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "keras_model_path = \"/kaggle/input/cnn/keras/default/1/brain_tumor_cnn.h5\"\n",
    "model = load_model(keras_model_path)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T17:17:46.390627Z",
     "iopub.status.busy": "2025-05-05T17:17:46.390079Z",
     "iopub.status.idle": "2025-05-05T17:18:48.878508Z",
     "shell.execute_reply": "2025-05-05T17:18:48.877945Z",
     "shell.execute_reply.started": "2025-05-05T17:17:46.390601Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:32<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1311 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746465522.905759     110 service.cc:148] XLA service 0x7e5cf00094f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1746465522.908637     110 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1746465522.908660     110 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1746465523.058605     110 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 4/41\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 54ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746465524.815395     110 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 99ms/step\n",
      "Accuracy: 0.30892448512585813\n"
     ]
    }
   ],
   "source": [
    "# Paths and config\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMG_SIZE = 224\n",
    "denoised_dir = \"/kaggle/working/denoised_test\"\n",
    "converted_dir = \"/kaggle/working/converted_for_keras\"\n",
    "keras_model_path = \"/kaggle/input/cnn/keras/default/1/brain_tumor_cnn.h5\"  # Replace with your model\n",
    "denoise_model = \"\"\n",
    "\n",
    "# Run all steps\n",
    "class_names = test_loader.dataset.classes\n",
    "\n",
    "denoise_images(denoise_model, noise_scheduler, test_loader, device, denoised_dir, class_names)\n",
    "convert_images_to_rgb_resize(denoised_dir, converted_dir, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "accuracy = evaluate_keras_model(keras_model_path, converted_dir, IMG_SIZE)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7335484,
     "sourceId": 11687337,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 330103,
     "modelInstanceId": 309732,
     "sourceId": 374660,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 330160,
     "modelInstanceId": 309791,
     "sourceId": 374742,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
